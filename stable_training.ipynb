{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stable_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UoK0sWEypQ-s",
        "colab": {}
      },
      "source": [
        "#%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Osqh5JlNpQ-2",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "import torch.utils.data as data_utils\n",
        "#from utils import epoch, epoch_robust_bound, epoch_calculate_robust_err, Flatten, generate_kappa_schedule_CIFAR, generate_epsilon_schedule_CIFAR\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-i2EPi3cBM",
        "colab_type": "code",
        "outputId": "5cf22ff7-7388-482f-95fe-41ac8dbd1985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuWv5TZpukKi",
        "colab_type": "text"
      },
      "source": [
        "# Utils and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kiV7tfS5c5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XdcOwIVuv7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def epoch(loader, model, device, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp,_ = model(X)\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def bound_propagation(model, initial_bound):\n",
        "    l, u = initial_bound\n",
        "    bounds = []\n",
        "    bounds.append(initial_bound)\n",
        "    list_of_layers = list(model.children())\n",
        "    \n",
        "    for i in range(len(list_of_layers)):\n",
        "        layer = list_of_layers[i]\n",
        "        \n",
        "        if isinstance(layer, Flatten):\n",
        "            l_ = Flatten()(l)\n",
        "            u_ = Flatten()(u)\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            l_ = (layer.weight.clamp(min=0) @ l.t() + layer.weight.clamp(max=0) @ u.t() \n",
        "                  + layer.bias[:,None]).t()\n",
        "            u_ = (layer.weight.clamp(min=0) @ u.t() + layer.weight.clamp(max=0) @ l.t() \n",
        "                  + layer.bias[:,None]).t()\n",
        "            \n",
        "        elif isinstance(layer, nn.Conv2d):\n",
        "            l_ = (nn.functional.conv2d(l, layer.weight.clamp(min=0), bias=None, \n",
        "                                       stride=layer.stride, padding=layer.padding,\n",
        "                                       dilation=layer.dilation, groups=layer.groups) +\n",
        "                  nn.functional.conv2d(u, layer.weight.clamp(max=0), bias=None, \n",
        "                                       stride=layer.stride, padding=layer.padding,\n",
        "                                       dilation=layer.dilation, groups=layer.groups) +\n",
        "                  layer.bias[None,:,None,None])\n",
        "            \n",
        "            u_ = (nn.functional.conv2d(u, layer.weight.clamp(min=0), bias=None, \n",
        "                                       stride=layer.stride, padding=layer.padding,\n",
        "                                       dilation=layer.dilation, groups=layer.groups) +\n",
        "                  nn.functional.conv2d(l, layer.weight.clamp(max=0), bias=None, \n",
        "                                       stride=layer.stride, padding=layer.padding,\n",
        "                                       dilation=layer.dilation, groups=layer.groups) + \n",
        "                  layer.bias[None,:,None,None])\n",
        "            \n",
        "        elif isinstance(layer, nn.ReLU):\n",
        "            l_ = l.clamp(min=0)\n",
        "            u_ = u.clamp(min=0)\n",
        "            \n",
        "        bounds.append((l_, u_))\n",
        "        l,u = l_, u_\n",
        "    return bounds\n",
        "\n",
        "\n",
        "def interval_based_bound(model, c, bounds, idx):\n",
        "    # requires last layer to be linear\n",
        "    cW = c.t() @ model.last_linear.weight\n",
        "    cb = c.t() @ model.last_linear.bias\n",
        "    \n",
        "    l,u = bounds[-2]\n",
        "    return (cW.clamp(min=0) @ l[idx].t() + cW.clamp(max=0) @ u[idx].t() + cb[:,None]).t()\n",
        "\n",
        "\n",
        "def epoch_robust_bound(loader, model, epsilon_schedule, device, kappa_schedule, batch_counter, mse=False, opt=None):\n",
        "    robust_err = 0\n",
        "    total_robust_loss = 0\n",
        "    total_mse_loss = 0\n",
        "    total_ibp_loss = 0\n",
        "    \n",
        "    C = [-torch.eye(10).to(device) for _ in range(10)]\n",
        "    for y0 in range(10):\n",
        "        C[y0][y0,:] += 1\n",
        "    \n",
        "    for i,data in enumerate(loader,0):\n",
        "      \n",
        "        #if i>299:  #calculate only for 100 batches\n",
        "        #  break      \n",
        "        \n",
        "        mse_loss_list = []\n",
        "        lower_bounds = []\n",
        "        upper_bounds = []\n",
        "        \n",
        "        \n",
        "        X,y = data\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        \n",
        "        ###### fit loss calculation ######\n",
        "        yp,_ = model(X)\n",
        "        fit_loss = nn.CrossEntropyLoss()(yp,y)\n",
        "    \n",
        "        ###### robust loss calculation ######\n",
        "        initial_bound = (X - epsilon_schedule[batch_counter], X + epsilon_schedule[batch_counter])\n",
        "        bounds = bound_propagation(model, initial_bound)\n",
        "        robust_loss = 0\n",
        "        for y0 in range(10):\n",
        "            if sum(y==y0) > 0:\n",
        "                lower_bound = interval_based_bound(model, C[y0], bounds, y==y0)\n",
        "                robust_loss += nn.CrossEntropyLoss(reduction='sum')(-lower_bound, y[y==y0]) / X.shape[0]\n",
        "                \n",
        "                robust_err += (lower_bound.min(dim=1)[0] < 0).sum().item() #increment when true label is not winning       \n",
        "        \n",
        "        total_robust_loss += robust_loss.item() * X.shape[0]  \n",
        "        \n",
        "        ##### MSE Loss #####\n",
        "        \n",
        "        indices_of_layers = [2,4,7,8] #CNN_small\n",
        "        #indices_of_layers = [2,4,6,8,11,13,14] #CNN_medium\n",
        "        \n",
        "        \n",
        "        for i in range(len(indices_of_layers)):\n",
        "            lower_bounds.append(Flatten()(bounds[indices_of_layers[i]][0])) #lower bounds \n",
        "            upper_bounds.append(Flatten()(bounds[indices_of_layers[i]][1])) #upper bounds \n",
        "            mse_loss_list.append(nn.MSELoss()(lower_bounds[i], upper_bounds[i]))\n",
        "            #mse_loss_list.append(RMSELoss(lower_bounds[i], upper_bounds[i]))\n",
        "            #mse_loss_list.append(Log_Product_Loss(lower_bounds[i], upper_bounds[i]))\n",
        "            #mse_loss_list.append(MAELoss(lower_bounds[i], upper_bounds[i]))\n",
        "            #mse_loss_list.append(Log_Product_MAE(lower_bounds[i], upper_bounds[i]))\n",
        "            \n",
        "        \n",
        "        mse_loss = mse_loss_list[0] + mse_loss_list[1] + mse_loss_list[2] #+ mse_loss_list[3] + mse_loss_list[4] + mse_loss_list[5] + mse_loss_list[6]\n",
        "        total_mse_loss += mse_loss.item()\n",
        "        \n",
        "        ###### combined losss ######\n",
        "        \n",
        "        ibp_loss = kappa_schedule[batch_counter]*fit_loss + (1-kappa_schedule[batch_counter])*robust_loss\n",
        "        \n",
        "        if (mse==True): combined_loss =  ibp_loss + mse_loss\n",
        "        else: combined_loss =  ibp_loss\n",
        "\n",
        "        total_ibp_loss += ibp_loss.item()\n",
        "        \n",
        "        batch_counter +=1\n",
        "         \n",
        "        if opt:\n",
        "            opt.zero_grad()\n",
        "            combined_loss.backward()\n",
        "            opt.step() \n",
        "        \n",
        "    return robust_err / len(loader.dataset), total_ibp_loss / len(loader.dataset), total_mse_loss/ len(loader.dataset)\n",
        "\n",
        "        \n",
        "def epoch_calculate_robust_err (loader, model, epsilon, device):\n",
        "    robust_err = 0.0\n",
        "    \n",
        "    C = [-torch.eye(10).to(device) for _ in range(10)]\n",
        "    for y0 in range(10):\n",
        "        C[y0][y0,:] += 1\n",
        "\n",
        "\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        \n",
        "        initial_bound = (X - epsilon, X + epsilon)\n",
        "        bounds = bound_propagation(model, initial_bound)\n",
        "\n",
        "        for y0 in range(10):\n",
        "            if sum(y==y0) > 0:\n",
        "                lower_bound = interval_based_bound(model, C[y0], bounds, y==y0)                \n",
        "                robust_err += (lower_bound.min(dim=1)[0] < 0).sum().item() #increment when true label is not winning       \n",
        "        \n",
        "    return robust_err / len(loader.dataset)\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "def generate_kappa_schedule_MNIST():\n",
        "\n",
        "    kappa_schedule = 2000*[1] # warm-up phase\n",
        "    kappa_value = 1.0\n",
        "    step = 0.5/58000\n",
        "    \n",
        "    for i in range(58000):\n",
        "        kappa_value = kappa_value - step\n",
        "        kappa_schedule.append(kappa_value)\n",
        "    \n",
        "    return kappa_schedule\n",
        "\n",
        "def generate_epsilon_schedule_MNIST(epsilon_train):\n",
        "    \n",
        "    epsilon_schedule = []\n",
        "    step = epsilon_train/10000\n",
        "            \n",
        "    for i in range(10000):\n",
        "        epsilon_schedule.append(i*step) #ramp-up phase\n",
        "    \n",
        "    for i in range(50000):\n",
        "        epsilon_schedule.append(epsilon_train)\n",
        "        \n",
        "    return epsilon_schedule\n",
        "\n",
        "\n",
        "def generate_kappa_schedule_CIFAR():\n",
        "\n",
        "    kappa_schedule = 10000*[1] # warm-up phase\n",
        "    kappa_value = 1.0\n",
        "    step = 0.5/340000\n",
        "    \n",
        "    for i in range(340000):\n",
        "        kappa_value = kappa_value - step\n",
        "        kappa_schedule.append(kappa_value)\n",
        "    \n",
        "    return kappa_schedule\n",
        "\n",
        "def generate_epsilon_schedule_CIFAR(epsilon_train):\n",
        "    \n",
        "    epsilon_schedule = []\n",
        "      \n",
        "    for i in range(350000):\n",
        "      epsilon_schedule.append(epsilon_train)\n",
        "        \n",
        "    return epsilon_schedule \n",
        "  \n",
        "  \n",
        "def pgd_linf_rand(model, X, y, epsilon, alpha, num_iter, restarts):\n",
        "    \"\"\" Construct PGD adversarial examples on the samples X, with random restarts\"\"\"\n",
        "    max_loss = torch.zeros(y.shape[0]).to(y.device)\n",
        "    max_delta = torch.zeros_like(X)\n",
        "    \n",
        "    for i in range(restarts):\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "        \n",
        "        for t in range(num_iter):\n",
        "            loss = nn.CrossEntropyLoss()(model(X + delta)[0], y)\n",
        "            loss.backward()\n",
        "            delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "            delta.grad.zero_()\n",
        "        \n",
        "        all_loss = nn.CrossEntropyLoss(reduction='none')(model(X+delta)[0],y)\n",
        "        max_delta[all_loss >= max_loss] = delta.detach()[all_loss >= max_loss]\n",
        "        max_loss = torch.max(max_loss, all_loss)\n",
        "        \n",
        "    return max_delta\n",
        "\n",
        "\n",
        "def epoch_adversarial(model, loader, attack, *args):\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y, *args)\n",
        "        yp = model(X+delta)[0]\n",
        "        loss = nn.CrossEntropyLoss()(yp,y)\n",
        "        \n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7bW3yTVvMLW",
        "colab_type": "text"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jMEAJ22NpQ-9",
        "outputId": "fcafee77-4706-4514-b829-a4bd09b9617a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9c19f0c6f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8QC_w0qavZy",
        "colab_type": "code",
        "outputId": "36253c75-f465-47d6-df39-3def178c00da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "mnist_train = datasets.MNIST(\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"./\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8243090.07it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135027.50it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2220189.35it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51324.56it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8CJe2L46pQ_z"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGimdiOImLDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_small(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(CNN_small, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 16, 4, padding=0, stride=2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 32, 4, padding=0, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.flat = Flatten()\n",
        "        self.linear1 = nn.Linear(32*10*10, 100)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.last_linear = nn.Linear(100, 10)                \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        hidden_activations = []\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        \n",
        "        x = self.flat(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        \n",
        "        out = self.last_linear(x)\n",
        "\n",
        "        \n",
        "        return out, hidden_activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pczaC9Iwwy3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_small().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KBRQTG-zpQ_3"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgFHqVWQpQ_4",
        "colab": {}
      },
      "source": [
        "EPSILON = 0.4\n",
        "EPSILON_TRAIN = 0.4\n",
        "kappa_schedule = generate_kappa_schedule_MNIST()\n",
        "\n",
        "#let's change epsilon schedule to more dynamic\n",
        "epsilon_schedule = []\n",
        "step = EPSILON_TRAIN/4000\n",
        "            \n",
        "for i in range(4000):\n",
        "  epsilon_schedule.append(i*step) #ramp-up phase\n",
        "for i in range(56000):\n",
        "  epsilon_schedule.append(EPSILON_TRAIN)\n",
        "\n",
        "batch_counter = 0\n",
        "filename1 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_IBP_test_error.txt'\n",
        "ibp_test_error = []\n",
        "filename2 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_IBP_verified_test_error.txt'\n",
        "ibp_verified_test_error = []\n",
        "filename3 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_IBP_mse_loss.txt'\n",
        "ibp_mse_loss = []\n",
        "\n",
        "\n",
        "\n",
        "mse = False\n",
        "model = CNN_small().to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(50):\n",
        "  _, ibp_loss, mse_loss = epoch_robust_bound(train_loader, model, epsilon_schedule, device, kappa_schedule, batch_counter, mse, opt)\n",
        "  batch_counter += 600\n",
        "  verified = epoch_calculate_robust_err(test_loader, model, EPSILON, device)\n",
        "  test_err,_ = epoch(test_loader, model, device)\n",
        "  \n",
        "  ibp_test_error.append(test_err)\n",
        "  ibp_verified_test_error.append(verified)\n",
        "  ibp_mse_loss.append(mse_loss)\n",
        "  print (t)\n",
        "  \n",
        "np.savetxt(filename1, ibp_test_error)\n",
        "np.savetxt(filename2, ibp_verified_test_error)\n",
        "np.savetxt(filename3, ibp_mse_loss)\n",
        "\n",
        "#############################################\n",
        "\n",
        "batch_counter = 0\n",
        "filename4 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_EXTRA_IBP_test_error.txt'\n",
        "extra_ibp_test_error = []\n",
        "filename5 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_EXTRA_IBP_verified_test_error.txt'\n",
        "extra_ibp_verified_test_error = []\n",
        "filename6 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_EXTRA_IBP_mse_loss.txt'\n",
        "extra_ibp_mse_loss = []\n",
        "\n",
        "mse = True\n",
        "model = CNN_small().to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(50):\n",
        "  _, ibp_loss, mse_loss = epoch_robust_bound(train_loader, model, epsilon_schedule, device, kappa_schedule, batch_counter, mse, opt)\n",
        "  batch_counter += 600\n",
        "  verified = epoch_calculate_robust_err(test_loader, model, EPSILON, device)\n",
        "  test_err,_ = epoch(test_loader, model, device)\n",
        "  \n",
        "  extra_ibp_test_error.append(test_err)\n",
        "  extra_ibp_verified_test_error.append(verified)\n",
        "  extra_ibp_mse_loss.append(mse_loss)\n",
        "  print (t)\n",
        "  \n",
        "np.savetxt(filename4, extra_ibp_test_error)\n",
        "np.savetxt(filename5, extra_ibp_verified_test_error)\n",
        "np.savetxt(filename6, extra_ibp_mse_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VpY6qopTw6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ibp_tab = []\n",
        "filename1 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_IBP.txt'\n",
        "ibp_tab = np.loadtxt(filename1)\n",
        "filename2 = '/content/gdrive/My Drive/Colab Notebooks/results/stable_training_MNIST_extra_loss.txt'\n",
        "extra_loss_tab = []\n",
        "extra_loss_tab = np.loadtxt(filename2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUzUmBFFWJcv",
        "colab_type": "code",
        "outputId": "25b35cbc-9780-4de9-cbd0-57a34b40df0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "x  = [i for i in range(0,31)]\n",
        "\n",
        "plt.plot(x,np.concatenate([[0.95],ibp_tab]), label=\"IBP\")\n",
        "plt.plot(x,np.concatenate([[0.95],extra_loss_tab]),  label=\"IBP_extra_loss\")\n",
        "plt.plot()\n",
        "plt.xticks(np.arange(min(x), max(x)+1, 2.0))\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Averaged Test Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf6SAJhKsb06yAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btbdu4QybWki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}